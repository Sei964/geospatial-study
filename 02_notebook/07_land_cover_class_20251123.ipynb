{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e3f6198b-979b-4a9c-9fae-ac987efc2952",
   "metadata": {},
   "source": [
    "07_land_cover_class_20251123.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "329ae111-8202-4e40-b9a4-0ac9d969afb3",
   "metadata": {},
   "source": [
    "# 次の課題: 土地被覆分類（Land Cover Classification）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5822c936-b90a-459f-abe1-6c1179b445bc",
   "metadata": {},
   "source": [
    "これまでの課題で、あなたはフィルタリング、雲除去、合成、$\\text{NDVI}$ の計算、時系列分析という、$\\text{GEE}$ の主要な分析技術を全て習得しました。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "929d0a46-1013-436b-aa1c-abcb67b44c6e",
   "metadata": {},
   "source": [
    "次のレベルに進み、抽出した画像を**情報**へと変換する、**教師あり分類 (Supervised Classification)** に挑戦しましょう。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c293b9d-cda7-4a9c-899a-6e692d8e2c14",
   "metadata": {},
   "source": [
    "## 新しいゴール: 琵琶湖周辺の土地被覆マップを作成する"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4de77ecd-44c0-4078-9754-edbf804f265b",
   "metadata": {},
   "source": [
    "この課題では、機械学習のアルゴリズム（例: $\\text{Random Forest}$）を使用して、画像内の各ピクセルを「水」「森林」「都市」「農地」などのカテゴリーに分類します。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8822032-bc41-4974-acf7-3cd1bbca08fc",
   "metadata": {},
   "source": [
    "#### **Guiding Question**:教師あり分類を実行するために、最初に必要となる最も重要なデータセットは何でしょうか？（ヒント: アルゴリズムに「これは水である」「これは森林である」と教えるためのデータです）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fba1d603-d50c-4adc-ab95-970011688e15",
   "metadata": {},
   "source": [
    "#### **Guiding Questionの解答**\n",
    "---\n",
    "<span style='color:red'>トレーニングデータ（学習データ)</span>が最も重要であり、不可欠な要素です。\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8708ff5-6f25-4d47-8155-abbbcdc5c882",
   "metadata": {},
   "source": [
    "### **ステップ18: トレーニングデータの収集（$\\text{ROI}$ の定義）**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9779035d-891e-4ee5-81b6-479aec16d1e0",
   "metadata": {},
   "source": [
    "トレーニングデータとは、「このピクセルは森林だ」「このピクセルは水だ」という正解ラベルを $\\text{GEE}$ の機械学習アルゴリズムに教えるためのサンプルデータです。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d6debf4-38a0-40a8-afc5-d1eeb4d28638",
   "metadata": {},
   "source": [
    "$\\text{GEE}$ では、このトレーニングデータはフィーチャコレクション（FeatureCollection）として格納されます。各フィーチャは<span style='color:blue'>ジオメトリ（幾何図形）</span>と<span style='color:blue'>クラス名（ラベル）</span>を持っています。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac0bd130-fbe0-461d-b599-cc3d5bc74105",
   "metadata": {},
   "source": [
    "まず、琵琶湖から水のサンプルとなるジオメトリ（ポリゴン）を定義しましょう。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7fb6316-1434-4cd9-b6d2-93d1f5d76378",
   "metadata": {},
   "source": [
    "#### **Guiding Question**: 琵琶湖の湖面の一部（例：$\\text{[136.0, 35.2], [136.1, 35.2], [136.1, 35.3], [136.0, 35.3]}$）を囲むポリゴンを定義し、water_polygon という変数に格納するには、どのように $\\text{ee.Geometry.Polygon()}$ を使えばよいでしょうか？"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce5696b-64c7-4657-ba0d-3677d9873c2b",
   "metadata": {},
   "source": [
    "Ref: [ee.Geometry.Polygon](https://developers.google.com/earth-engine/apidocs/ee-geometry-polygon?_gl=1*1aofsir*_up*MQ..*_ga*MTIyODE2NTA5OS4xNzYzOTI5MDkw*_ga_SM8HXJ53K2*czE3NjM5MjkwOTAkbzEkZzAkdDE3NjM5MjkwOTAkajYwJGwwJGgw&hl=ja)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80e4164d-ef09-4b43-b293-191430a3919b",
   "metadata": {},
   "source": [
    "#### **Guiding Questionの解答**\n",
    "---\n",
    "```python\n",
    "polygon_coords = [\n",
    "    [[136.0, 35.2], [136.1, 35.2], \n",
    "     [136.1, 35.3], [136.0, 35.3]]\n",
    "]\n",
    "\n",
    "water_polygon = ee.Geometry.Polygon(polygon_coords)\n",
    "```  \n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57d3e400-34b9-47bb-b0c8-602ed38975cf",
   "metadata": {},
   "source": [
    "### **ステップ19: ジオメトリへのラベル付け**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07bd0625-e5a0-4068-822b-5e55ddebcffd",
   "metadata": {},
   "source": [
    "このジオメトリを機械学習アルゴリズムのトレーニングデータとして使用するには、「これは水である」という<span style='color:red'>ラベル（正解）</span>を付与する必要があります。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9b1acc3-929d-4069-90ce-2379474421f0",
   "metadata": {},
   "source": [
    "$\\text{GEE}$ では、これは**数値**のプロパティとして定義されます。\n",
    "- **水域 (Water)**: $\\text{landcover} = 0$\n",
    "- **森林 (Forest)**: $\\text{landcover} = 1$\n",
    "- **都市 (Urban)**: $\\text{landcover} = 2$ \n",
    "\n",
    "このラベルとジオメトリを組み合わせるには、`ee.Feature()` を使用します。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d7a9687-9636-4e15-96a4-492517f6b7ac",
   "metadata": {},
   "source": [
    "#### **Guiding Question**: 定義した water_polygon を使って、landcover の値が 0 であるフィーチャ（特徴）を定義し、water_feature という変数に格納するには、どのようにコードを記述すればよいでしょうか？  (ヒント: $\\text{ee.Feature(ジオメトリ, プロパティ\\{...\\})}$ という形式を使います。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "701f03fe-a879-4690-bff7-854067bcb16f",
   "metadata": {},
   "source": [
    "#### **Guiding Questionの解答**\n",
    "---\n",
    "```python\n",
    "# 修正点: ジオメトリの後にプロパティ（辞書）を追加\n",
    "water_feature = ee.Feature(water_polygon, {'landcover': 0})\n",
    "```\n",
    ">このフィーチャにラベル（landcover）を付与しないと、アルゴリズムはこれが「水」であることを学習できません。フィーチャを作成する際は、ジオメトリの後にプロパティを辞書形式で渡す必要があります。<span style='color:red'>{'landcover' : 0}</span>は水域であることを示す。\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4bd3b18-a69c-48f9-8ab0-db7570b3ff25",
   "metadata": {},
   "source": [
    "### **ステップ20: 森林のサンプルの作成**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a49b860f-7fef-4a2c-88fe-2852115c66a4",
   "metadata": {},
   "source": [
    "機械学習を機能させるには、異なるカテゴリのサンプルが必要です。次に、琵琶湖の南の山地で森林のサンプルを作成しましょう（$\\text{landcover} = 1$）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d5459e6-5372-46c6-ab9d-0545cb3f661c",
   "metadata": {},
   "source": [
    "#### **Guiding Question**: 以下の座標を使って**森林のポリゴン**を定義し、それをラベル $\\text{landcover}=1$ を持つフィーチャ forest_feature として作成するには、どのようにコードを記述すればよいでしょうか？\n",
    "- **森林の座標**: $\\text{[136.0, 34.9], [136.1, 34.9], [136.1, 35.0], [136.0, 35.0]}$\n",
    "  \n",
    "**(水域フィーチャのコードを参考にしてください)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "424efcba-ea4c-4d17-ab1a-6e4a97c334f7",
   "metadata": {},
   "source": [
    "#### **Guiding Questionの解答**\n",
    "---\n",
    "```python\n",
    "forest_coords = [\n",
    "    [[136.0, 34.9], [136.1, 34.9], \n",
    "     [136.1, 35.0], [136.0, 35.0]]\n",
    "]\n",
    "\n",
    "forest_polygon = ee.Geometry.Polygon(forest_coords)\n",
    "\n",
    "forest_feature = ee.Feature(forest_polygon, {'landcover':1})\n",
    "```\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "219b9c6f-46ed-4476-9ca3-adaf077916f5",
   "metadata": {},
   "source": [
    "### **ステップ21: トレーニングデータの統合**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b90556a-b3dc-4a60-9f04-855e32f9fa85",
   "metadata": {},
   "source": [
    "これで、2つのトレーニングサンプル（`water_feature` と `forest_feature）`ができました。機械学習モデルが学習するためには、これらのサンプルを<span style='color:blue'>一つの集合体（コレクション)</span>にまとめる必要があります。\n",
    "\n",
    "このコレクションは、`ee.FeatureCollection()` を使って作成します。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6656e188-decd-4064-9c6b-af089d3fd02e",
   "metadata": {},
   "source": [
    "#### **Guiding Question**: 作成した `water_feature` と `forest_feature` をリストとして渡し、最終的なトレーニングデータセット `training_data` を作成するには、どのようにコードを記述すればよいでしょうか？"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0506c016-0c46-44cc-b889-c9af38cc7df2",
   "metadata": {},
   "source": [
    "#### **Guiding Questionの解答**\n",
    "---\n",
    "```python\n",
    "list_of_features = [\n",
    "    water_feature, forest_feature\n",
    "]\n",
    "\n",
    "training_data = ee.FeatureCollection(list_of_features)\n",
    "```\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03838bf7-b07c-4d17-905a-25a4801c1fc6",
   "metadata": {},
   "source": [
    "### **ステップ22: 分類に使用するバンド（フィーチャ）の選択**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47d8a516-c913-4f12-9286-e170017eb847",
   "metadata": {},
   "source": [
    "機械学習アルゴリズムは、$\\text{SR\\_B4}, \\text{SR\\_B3}, \\text{SR\\_B2}$ の3バンドだけでなく、画像が持つ**すべての情報**を判断材料として使用することで、精度が向上します。  \n",
    "\n",
    "分類に用いる入力データ（フィーチャ）として、熱バンドを除く Landsat 9 の反射率バンド（$\\text{SR\\_B2}$ から $\\text{SR\\_B7}$ まで）を使用しましょう。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f429dd5-404c-4322-a303-f2daca354bda",
   "metadata": {},
   "source": [
    "#### **Guiding Question**: 以下の6つのバンド名をリストとして定義し、`input_bands` という変数に格納してください。\n",
    "\n",
    "- **青、緑、赤、近赤外、短波赤外1、短波赤外2**\n",
    "- $\\text{SR\\_B2}, \\text{SR\\_B3}, \\text{SR\\_B4}, \\text{SR\\_B5}, \\text{SR\\_B6}, \\text{SR\\_B7}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fe9be36-f816-4264-b611-32405148b1eb",
   "metadata": {},
   "source": [
    "#### **Guiding Questionの解答**\n",
    "---\n",
    "```python\n",
    "input_bands = ['SR_B2', 'SR_B3', 'SR_B4', 'SR_B5', 'SR_B6', 'SR_B7']\n",
    "```\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b27aa49d-5313-47e9-bdc0-a37d5c1e0bb0",
   "metadata": {},
   "source": [
    "### **ステップ23: ピクセルデータのサンプリング**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79eaadea-2973-406d-ae71-8047ae6ab568",
   "metadata": {},
   "source": [
    "教師あり分類を行うには、まず、トレーニングポリゴン（`training_data`）が示す場所の**実際のピクセル値**を、分類に使うバンド（`input_bands`）から抽出する必要があります。この作業をサンプリングと呼びます。\n",
    "\n",
    "これは `.sampleRegions()` メソッドを使って行います。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5c85cad-cf07-4a30-bdb6-2e95f0ca4b7a",
   "metadata": {},
   "source": [
    "#### **Guiding Question**: クラウドフリー合成画像（`final_composite`）から、`input_bands` の値をトレーニングデータに基づいて抽出し、`sampled_data` という変数に格納するには、どのようにコードを記述すればよいでしょうか？"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4990ec05-9bd6-4b22-85cc-f503d0f31f15",
   "metadata": {},
   "source": [
    "#### **Guiding Questionの解答**\n",
    "---\n",
    "```python\n",
    "# ヒント: final_compositeからバンドを選択し、sampleRegionsメソッドを呼び出す\n",
    "\n",
    "sampled_data = final_composite.select(input_bands).sampleRegions(\n",
    "    collection=training_data,  # トレーニングジオメトリ\n",
    "    properties=['landcover'],  # 正解ラベルのプロパティ名\n",
    "    scale=30                   # Landsatの解像度\n",
    ")\n",
    "```\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33524c0a-0150-4a84-a46e-dffdbaadfb2a",
   "metadata": {},
   "source": [
    ">[!success] サンプリングは成功です。\n",
    "\n",
    "これで、機械学習モデルの訓練に必要な全てのデータが整いました。\n",
    "\n",
    "- **入力データ**: sampled_data (各ピクセル行と、それに紐づくバンド値)\n",
    "- **正解ラベル**: landcover (0:水、1:森林)\n",
    "- **分類に使う特徴**: input_bands"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a4ba62b-d21c-4dae-b4bf-af6c3d044ab8",
   "metadata": {},
   "source": [
    "### **ステップ24: 分類器の訓練（Random Forest）**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0ecc1fc-ecca-4a29-b446-dc29ab7867e3",
   "metadata": {},
   "source": [
    "次に、最も標準的で精度の高いアルゴリズムの一つである $\\text{Random Forest}$ 分類器を初期化し、サンプリングしたデータを使って訓練します。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71b64bdf-6670-47bd-b4cb-09c8ef183ac1",
   "metadata": {},
   "source": [
    "#### **Guiding Question**: $\\text{ee.Classifier.smileRandomForest()}$ を使って分類器を初期化し、それに対して .train() メソッドを使って訓練（学習）を実行し、結果を trained_classifier という変数に格納するには、どのようにコードを記述すればよいでしょうか？  \n",
    "\n",
    "訓練には以下の3つの引数が必要です。\n",
    "\n",
    "1. `features`: `sampled_data`\n",
    "2. `classProperty`: `'landcover'` (正解ラベルのプロパティ名)\n",
    "3. `inputProperties`: `input_bands` (使用するバンドのリスト)\n",
    "\n",
    "```python\n",
    "# ヒント: ee.Classifier.smileRandomForest(ツリーの数).train(...)\n",
    "\n",
    "trained_classifier = # <ここに訓練コードを記述>\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "114e5582-8310-450c-8b8c-f6733b5e0592",
   "metadata": {},
   "source": [
    "#### **Guiding Questionの解答**\n",
    "---\n",
    "\n",
    "(X) ~~trained_classifier = ee.Classifier.smileRandomForest().train(sampled_data, 'landcover', input_bands)~~\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51efbd72-b90a-48ce-b5e5-8521802138c7",
   "metadata": {},
   "source": [
    "***Result***: **<span style='color:red'>TypeError</span>**\n",
    "---------------------------------------------------------------------------\n",
    "TypeError                                 Traceback (most recent call last)\n",
    "Cell In[25], line 1\n",
    "----> 1 trained_classifier = ee.Classifier.smileRandomForest().train(sampled_data, 'landcover', input_bands)\n",
    "\n",
    "TypeError: Classifier.smileRandomForest() missing 1 required positional argument: 'numberOfTrees'\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec306ce9-4b4c-4ac2-95b8-fe48e8bb3be4",
   "metadata": {},
   "source": [
    "**エラーの原因: 決定木 (Trees) の数**\n",
    "\n",
    "$\\text{ee.Classifier.smileRandomForest()}$ を呼び出す際、最低でも**いくつの決定木（numberOfTrees）を使用するか**を指定する必要があります。\n",
    "- **誤**: `ee.Classifier.smileRandomForest()`\n",
    "- **正**: `ee.Classifier.smileRandomForest(10)`\n",
    "\n",
    "決定木の数を $\\text{10}$ に設定して、以下の通り修正してください。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a422c20b-3f98-4963-ad81-3af9da55b40d",
   "metadata": {},
   "source": [
    "> そのコードを実行すると、$\\text{Random Forest}$ 分類器は、サンプリングしたピクセルデータ（sampled_data）を使って、ピクセル値と正解ラベル（landcover）の関係を学習します。\n",
    "\n",
    "これで、アルゴリズムは「どのピクセル値の組み合わせが水域（0）で、どの組み合わせが森林（1）か」を認識できるようになりました。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c231361-ce8f-4ee8-8f37-a90ef628105c",
   "metadata": {},
   "source": [
    "#### **Guiding Questionの解答**\n",
    "---\n",
    "**修正後の分類器の訓練**\n",
    "\n",
    "以下のコードを実行して、分類器を訓練してください。これでエラーは解消するはずです。\n",
    "```python\n",
    "#  修正点: 決定木の数 (10) を引数に追加\n",
    "trained_classifier = ee.Classifier.smileRandomForest(10).train(\n",
    "    sampled_data, \n",
    "    'landcover', \n",
    "    input_bands\n",
    ")\n",
    "```\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d7f6ab2-6bc1-40a1-a41c-a01788ed4325",
   "metadata": {},
   "source": [
    "### **ステップ25: 分類器の適用（地図化）**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23a19a9d-6008-40d5-9605-6c756742bbf5",
   "metadata": {},
   "source": [
    "最後に、訓練済みの分類器（`trained_classifier`）を、入力画像全体（`final_composite`）に適用し、土地被覆マップを作成します。\n",
    "\n",
    "これは、`.classify()` メソッドを使って行います。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cac8d933-527a-4293-9e04-75d8e0de1dc8",
   "metadata": {},
   "source": [
    "### **ステップ26: 分類マップの表示**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e30af5e2-4ce4-4f8a-a8b0-4b89761f23d0",
   "metadata": {},
   "source": [
    "分類後の画像は、元の反射率バンド（$\\text{SR\\_B*}$) ではなく、`classification` という名前の単一のバンドになります。このバンドには、各ピクセルが**0 (水域)** または **1 (森林)** の値で格納されています。この分類結果を地図上に色分けして表示するためのパラメータを定義しましょう。\n",
    "\n",
    "```python\n",
    "# 1. 分類器を画像全体に適用\n",
    "classified_image = final_composite.select(input_bands).classify(trained_classifier)\n",
    "\n",
    "# 2. 分類結果の視覚化パラメータを定義 (水域=0, 森林=1)\n",
    "classification_vis = {\n",
    "    'min': 0,\n",
    "    'max': 1,\n",
    "    'palette': ['0000FF', '008000']  # 0:青 (水域), 1:緑 (森林)\n",
    "}\n",
    "\n",
    "# 3. タイルURLを取得\n",
    "classification_map_id = classified_image.getMapId(classification_vis)\n",
    "classification_tile_url = classification_map_id['tile_fetcher'].url_format\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27e9fcb5-a49a-48ed-add6-bd89abd22d71",
   "metadata": {},
   "source": [
    "#### **Guiding Question**: 上記のコードを実行した後、以下のFoliumコードを使って地図にレイヤーを追加してください。表示された地図上で、分類器が**琵琶湖の湖面**と**周囲の森林**を、それぞれどのような色で塗分けているか教えていただけますか？"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b6f0593-49de-412f-a43f-a13128c7a88b",
   "metadata": {},
   "source": [
    "#### **Guiding Questionの解答**\n",
    "---\n",
    "```python\n",
    "# 既存の地図 'my_map' にレイヤーを追加\n",
    "folium.TileLayer(\n",
    "    tiles=classification_tile_url,\n",
    "    attr='Google Earth Engine',\n",
    "    name='Land Cover Classification (Water/Forest)',\n",
    "    overlay=True,\n",
    "    control=True\n",
    ").add_to(my_map)\n",
    "\n",
    "folium.LayerControl().add_to(my_map)\n",
    "display(my_map)\n",
    "```\n",
    "琵琶湖の湖面は青色、周囲の森林は緑色です。しかし、都市も緑色になっています。\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39852668-13ad-48a6-8190-d3e14563932f",
   "metadata": {},
   "source": [
    "**<span style='color:blue'>誤分類の原因</span>**  \n",
    "\n",
    "訓練に使用した分類器は、「水域 ($\\text{0}$) 」と「森林 ($\\text{1}$)」の2つのクラスしか学習していません。都市部（特に住宅地や公園）は、コンクリートだけでなく、**芝生や街路樹などの植生**も多く含んでいます。そのため、反射パターンが**森林（NIR反射が高い）に最も近く**なり、分類器は都市を**最も近いクラスである森林 ($\\text{緑}$) に誤分類**したのです。これを修正するには、3番目のクラス（都市）を追加して分類器を再訓練する必要があります。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef8940b5-17e4-409d-a592-4f996f00de58",
   "metadata": {},
   "source": [
    "### **ステップ27: 都市 (Urban) のトレーニングサンプルの追加**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fb4c8a6-1d7d-4d66-83f1-10771eb90bdb",
   "metadata": {},
   "source": [
    "**<span style='color:red'>都市（Urban）</span>**のクラス ($\\text{landcover} = 2$) を追加し、分類器が「森林と都市の違い」を学習できるようにしましょう。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b81b162a-acfa-4b7d-8831-9869baf52173",
   "metadata": {},
   "source": [
    "#### **Guiding Question**: 以下の座標を使って**都市のポリゴン**を定義し、それをラベル $\\text{landcover}=2$ を持つ**フィーチャ **`urban\\_feature` として作成するには、どのようにコードを記述すればよいでしょうか？ \n",
    "\n",
    "- **都市の座標**: $\\text{[135.9, 35.0], [136.0, 35.0], [136.0, 35.1], [135.9, 35.1]}$\n",
    "\n",
    "**(以前のフィーチャ定義コードを参考にしてください)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d0708cf-9001-4e5d-aff2-7bfe1aa17634",
   "metadata": {},
   "source": [
    "#### **Guiding Questionの解答**\n",
    "---\n",
    "```python\n",
    "urban_coords = [\n",
    "    [[135.9, 35.0], [136.0, 35.0], \n",
    "     [136.0, 35.1], [135.9, 35.1]]\n",
    "]\n",
    "\n",
    "urban_polygon = ee.Geometry.Polygon(urban_coords)\n",
    "\n",
    "urban_feature = ee.Feature(urban_polygon, {'landcover':2})\n",
    "\n",
    "```\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5557750-a318-4cfd-948c-b1a9ebd178fb",
   "metadata": {},
   "source": [
    "### **ステップ28: トレーニングデータの再統合と訓練**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a89edb4-dd7b-42e4-9aad-ee913e5d9e36",
   "metadata": {},
   "source": [
    "分類器が都市を森林と区別できるように、新しいフィーチャを含めて、**サンプリングと訓練のプロセス全体をやり直す**必要があります。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6460a2cb-58e1-4cfb-a54f-ca6ae3b009a1",
   "metadata": {},
   "source": [
    "1. **トレーニングデータの再統合**\n",
    "\n",
    "まず、3つのフィーチャをすべて含んだ新しい $\\text{FeatureCollection}$ を作成します。\n",
    "```python\n",
    "# 1. 3つのフィーチャを統合した新しいトレーニングデータセットを作成\n",
    "training_data = ee.FeatureCollection([\n",
    "    water_feature, \n",
    "    forest_feature, \n",
    "    urban_feature\n",
    "])\n",
    "```\n",
    "\n",
    "2. **再サンプリングと再訓練**\n",
    "次に、この新しいデータセットを使って画像をサンプリングし、分類器を再訓練します。\n",
    "```python\n",
    "# 2. 再サンプリング\n",
    "sampled_data = final_composite.select(input_bands).sampleRegions(\n",
    "    collection=training_data,\n",
    "    properties=['landcover'],\n",
    "    scale=30\n",
    ")\n",
    "\n",
    "# 3. 分類器の再訓練\n",
    "trained_classifier = ee.Classifier.smileRandomForest(10).train(\n",
    "    sampled_data, \n",
    "    'landcover', \n",
    "    input_bands\n",
    ")\n",
    "\n",
    "# 4. 分類器を画像全体に適用\n",
    "classified_image = final_composite.select(input_bands).classify(trained_classifier)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72ec7e84-926c-4773-913c-77334684d93d",
   "metadata": {},
   "source": [
    "### **ステップ29: 最終マップの表示と確認**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "509efca6-8152-451a-b597-5607f9f14a27",
   "metadata": {},
   "source": [
    "最後に、都市 ($\\text{2}$) に対応する色（赤）を追加して視覚化パラメータを更新し、最終マップを表示します。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de7ea95-17ca-4191-8c21-e791b261c535",
   "metadata": {},
   "source": [
    "#### **Guiding Question**: 上記のコードを実行した後、以下のFoliumコードを使って地図にレイヤーを追加してください。表示された地図上で、分類器が**水域**、**森林**、そして**都市**をそれぞれどのように色分けしているか教えていただけますか？"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cdfcd47-309c-499c-b41e-4ad41a47e61d",
   "metadata": {},
   "source": [
    "#### **Guiding Questionの解答**\n",
    "---\n",
    "```python\n",
    "# 5. 視覚化パラメータを更新 (水域=0, 森林=1, 都市=2)\n",
    "classification_vis = {\n",
    "    'min': 0,\n",
    "    'max': 2,\n",
    "    'palette': ['0000FF', '008000', 'FF0000']  # 0:青 (水), 1:緑 (森), 2:赤 (都市)\n",
    "}\n",
    "\n",
    "# 6. タイルURLを取得\n",
    "classification_map_id = classified_image.getMapId(classification_vis)\n",
    "classification_tile_url = classification_map_id['tile_fetcher'].url_format\n",
    "\n",
    "# 7. 既存の地図 'my_map' にレイヤーを追加\n",
    "folium.TileLayer(\n",
    "    tiles=classification_tile_url,\n",
    "    attr='Google Earth Engine',\n",
    "    name='Final Land Cover Classification',\n",
    "    overlay=True,\n",
    "    control=True\n",
    ").add_to(my_map)\n",
    "\n",
    "# 8. マップの表示\n",
    "folium.LayerControl().add_to(my_map)\n",
    "display(my_map)\n",
    "```\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "145b940a-c4a6-4d77-9cb4-c92105ea79d9",
   "metadata": {},
   "source": [
    "## ***<span style='color:orange'>Complete Code</span>***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "b6b4c928-0599-4fdb-afab-44aae8069150",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ee\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "9451e206-f2c9-4228-b0be-c4cac714663c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ee.Initialize(project='earth-change-analysis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "263832e1-758c-4bc6-a9fe-cb3a7a90ff8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define coordinates for a polygon (e.g., a square)\n",
    "# The last coordinate should typically be the same as the first to close the polygon.\n",
    "water_coords = [\n",
    "    [[136.0, 35.2], [136.1, 35.2], \n",
    "     [136.1, 35.3], [136.0, 35.3]]\n",
    "]\n",
    "\n",
    "# Create the polygon\n",
    "water_polygon = ee.Geometry.Polygon(water_coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "f1bfcacf-584c-445e-a588-afa75bedb82b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'type': 'Polygon', 'coordinates': [[[136, 35.2], [136.1, 35.2], [136.1, 35.3], [136, 35.3], [136, 35.2]]]}\n"
     ]
    }
   ],
   "source": [
    "print(water_polygon.getInfo())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "745e489e-add1-4f0f-9902-5b988bd09a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "water_feature = ee.Feature(water_polygon, {'landcover': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "79f6857e-bd29-41d4-93ef-639ffe88327c",
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_coords = [\n",
    "    [[136.0, 34.9], [136.1, 34.9], \n",
    "     [136.1, 35.0], [136.0, 35.0]]\n",
    "]\n",
    "\n",
    "forest_polygon = ee.Geometry.Polygon(forest_coords)\n",
    "\n",
    "forest_feature = ee.Feature(forest_polygon, {'landcover':1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "e098649a-1a57-4e23-a56c-a26dde6a82f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "urban_coords = [\n",
    "    [[135.9, 35.0], [136.0, 35.0], \n",
    "     [136.0, 35.1], [135.9, 35.1]]\n",
    "]\n",
    "\n",
    "urban_polygon = ee.Geometry.Polygon(urban_coords)\n",
    "\n",
    "urban_feature = ee.Feature(urban_polygon, {'landcover':2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "f62a5881-c788-489b-bf01-5956137172d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 3つのフィーチャを統合した新しいトレーニングデータセットを作成\n",
    "training_data = ee.FeatureCollection([\n",
    "    water_feature, \n",
    "    forest_feature, \n",
    "    urban_feature\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "6aae7469-efbb-421a-b285-df92fd7e5083",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_bands = ['SR_B2', 'SR_B3', 'SR_B4', 'SR_B5', 'SR_B6', 'SR_B7']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "1bfc5a3b-2d3c-46ef-83f1-d974472a20c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "biwako_point = ee.Geometry.Point([136.17, 35.10])\n",
    "longitude, latitude = biwako_point.coordinates().getInfo() # 地図の中心座標を取得"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "9b3487bd-caf4-4c65-8e45-a1a35508cc20",
   "metadata": {},
   "outputs": [],
   "source": [
    "end_date = '2025-11-17' \n",
    "start_date = (datetime.datetime.strptime(end_date, '%Y-%m-%d') - datetime.timedelta(days=365)).strftime('%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "92185d76-a914-4072-b8da-31d44ab045d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "l9_collection = ee.ImageCollection('LANDSAT/LC09/C02/T1_L2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "62f37768-b1f2-4f77-bd6a-e6691773adc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_collection = l9_collection \\\n",
    "    .filterDate(start_date, end_date) \\\n",
    "    .filterBounds(biwako_point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "b46fbb51-115f-4e65-a604-184fa5c2530d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_clouds(image):\n",
    "    # 1. QA_PIXELバンドを選択\n",
    "    qa = image.select('QA_PIXEL')\n",
    "    \n",
    "    # 2. 雲の重みを定義\n",
    "    # Bit 3 (Cloud) = 8, Bit 1 (Dilated Cloud) = 2\n",
    "    \n",
    "    # 3. 雲・希釈雲の両方ではないピクセルをTrueとするマスクを作成\n",
    "    mask = qa.bitwiseAnd(8).eq(0).And(  \n",
    "             qa.bitwiseAnd(2).eq(0))   \n",
    "           \n",
    "    # 4. マスクを画像に適用\n",
    "    return image.updateMask(mask)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "313d7f9c-6a5f-4727-96c1-0a097082e221",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 雲除去関数をコレクション内のすべての画像に適用\n",
    "cloud_free_collection = filtered_collection.map(mask_clouds)\n",
    "\n",
    "# 雲除去されたコレクション全体の中央値を計算し、1枚の合成画像を生成\n",
    "final_composite = cloud_free_collection.median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "ef46d0e9-6ede-4d75-b510-09b386a65f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_data = final_composite.select(input_bands).sampleRegions(\n",
    "    collection=training_data,  # トレーニングジオメトリ\n",
    "    properties=['landcover'],  # 正解ラベルのプロパティ名\n",
    "    scale=30                   # Landsatの解像度\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "f6ffbd99-a609-4f48-aab5-72aa2e076615",
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_classifier = ee.Classifier.smileRandomForest(10).train(\n",
    "    sampled_data, \n",
    "    'landcover', \n",
    "    input_bands\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "093b0441-408e-4469-80ee-208a4700191b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 分類器を画像全体に適用\n",
    "classified_image = final_composite.select(input_bands).classify(trained_classifier)\n",
    "\n",
    "# 2. 分類結果の視覚化パラメータを定義 (水域=0, 森林=1)\n",
    "# 5. 視覚化パラメータを更新 (水域=0, 森林=1, 都市=2)\n",
    "classification_vis = {\n",
    "    'min': 0,\n",
    "    'max': 2,\n",
    "    'palette': ['0000FF', '008000', 'FF0000']  # 0:青 (水), 1:緑 (森), 2:赤 (都市)\n",
    "}\n",
    "\n",
    "# 3. タイルURLを取得\n",
    "classification_map_id = classified_image.getMapId(classification_vis)\n",
    "classification_tile_url = classification_map_id['tile_fetcher'].url_format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "b5387445-6b2b-42f5-b854-daa2dd7b9fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import folium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "36443507-7e92-4b70-a32e-2b4f60621b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_map = folium.Map(\n",
    "        location=[latitude, longitude],   # 地図の中心座標\n",
    "        zoom_start=10,                    # 初期ズームレベル (琵琶湖周辺)\n",
    "        tiles=basemaps['Google Satellite Hybrid'] # 初期タイルを設定\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "fb5e50a4-10ad-44df-b829-83635c25b2ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"width:100%;\"><div style=\"position:relative;width:100%;height:0;padding-bottom:60%;\"><span style=\"color:#565656\">Make this Notebook Trusted to load map: File -> Trust Notebook</span><iframe srcdoc=\"&lt;!DOCTYPE html&gt;\n",
       "&lt;html&gt;\n",
       "&lt;head&gt;\n",
       "    \n",
       "    &lt;meta http-equiv=&quot;content-type&quot; content=&quot;text/html; charset=UTF-8&quot; /&gt;\n",
       "    &lt;script src=&quot;https://cdn.jsdelivr.net/npm/leaflet@1.9.3/dist/leaflet.js&quot;&gt;&lt;/script&gt;\n",
       "    &lt;script src=&quot;https://code.jquery.com/jquery-3.7.1.min.js&quot;&gt;&lt;/script&gt;\n",
       "    &lt;script src=&quot;https://cdn.jsdelivr.net/npm/bootstrap@5.2.2/dist/js/bootstrap.bundle.min.js&quot;&gt;&lt;/script&gt;\n",
       "    &lt;script src=&quot;https://cdnjs.cloudflare.com/ajax/libs/Leaflet.awesome-markers/2.0.2/leaflet.awesome-markers.js&quot;&gt;&lt;/script&gt;\n",
       "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/npm/leaflet@1.9.3/dist/leaflet.css&quot;/&gt;\n",
       "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/npm/bootstrap@5.2.2/dist/css/bootstrap.min.css&quot;/&gt;\n",
       "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://netdna.bootstrapcdn.com/bootstrap/3.0.0/css/bootstrap-glyphicons.css&quot;/&gt;\n",
       "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.2.0/css/all.min.css&quot;/&gt;\n",
       "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdnjs.cloudflare.com/ajax/libs/Leaflet.awesome-markers/2.0.2/leaflet.awesome-markers.css&quot;/&gt;\n",
       "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/gh/python-visualization/folium/folium/templates/leaflet.awesome.rotate.min.css&quot;/&gt;\n",
       "    \n",
       "            &lt;meta name=&quot;viewport&quot; content=&quot;width=device-width,\n",
       "                initial-scale=1.0, maximum-scale=1.0, user-scalable=no&quot; /&gt;\n",
       "            &lt;style&gt;\n",
       "                #map_1bdc5db1d3ae07d87f9b6ae72721de15 {\n",
       "                    position: relative;\n",
       "                    width: 100.0%;\n",
       "                    height: 100.0%;\n",
       "                    left: 0.0%;\n",
       "                    top: 0.0%;\n",
       "                }\n",
       "                .leaflet-container { font-size: 1rem; }\n",
       "            &lt;/style&gt;\n",
       "\n",
       "            &lt;style&gt;html, body {\n",
       "                width: 100%;\n",
       "                height: 100%;\n",
       "                margin: 0;\n",
       "                padding: 0;\n",
       "            }\n",
       "            &lt;/style&gt;\n",
       "\n",
       "            &lt;style&gt;#map {\n",
       "                position:absolute;\n",
       "                top:0;\n",
       "                bottom:0;\n",
       "                right:0;\n",
       "                left:0;\n",
       "                }\n",
       "            &lt;/style&gt;\n",
       "\n",
       "            &lt;script&gt;\n",
       "                L_NO_TOUCH = false;\n",
       "                L_DISABLE_3D = false;\n",
       "            &lt;/script&gt;\n",
       "\n",
       "        \n",
       "&lt;/head&gt;\n",
       "&lt;body&gt;\n",
       "    \n",
       "    \n",
       "            &lt;div class=&quot;folium-map&quot; id=&quot;map_1bdc5db1d3ae07d87f9b6ae72721de15&quot; &gt;&lt;/div&gt;\n",
       "        \n",
       "&lt;/body&gt;\n",
       "&lt;script&gt;\n",
       "    \n",
       "    \n",
       "            var map_1bdc5db1d3ae07d87f9b6ae72721de15 = L.map(\n",
       "                &quot;map_1bdc5db1d3ae07d87f9b6ae72721de15&quot;,\n",
       "                {\n",
       "                    center: [35.1, 136.17],\n",
       "                    crs: L.CRS.EPSG3857,\n",
       "                    ...{\n",
       "  &quot;zoom&quot;: 10,\n",
       "  &quot;zoomControl&quot;: true,\n",
       "  &quot;preferCanvas&quot;: false,\n",
       "}\n",
       "\n",
       "                }\n",
       "            );\n",
       "\n",
       "            \n",
       "\n",
       "        \n",
       "    \n",
       "            var tile_layer_a2c2f59cb7a20d97e6e7bb024c003156 = L.tileLayer(\n",
       "                &quot;https://mt1.google.com/vt/lyrs=y\\u0026x={x}\\u0026y={y}\\u0026z={z}&quot;,\n",
       "                {\n",
       "  &quot;minZoom&quot;: 0,\n",
       "  &quot;maxZoom&quot;: 18,\n",
       "  &quot;maxNativeZoom&quot;: 18,\n",
       "  &quot;noWrap&quot;: false,\n",
       "  &quot;attribution&quot;: &quot;Google&quot;,\n",
       "  &quot;subdomains&quot;: &quot;abc&quot;,\n",
       "  &quot;detectRetina&quot;: false,\n",
       "  &quot;tms&quot;: false,\n",
       "  &quot;opacity&quot;: 1,\n",
       "}\n",
       "\n",
       "            );\n",
       "        \n",
       "    \n",
       "            tile_layer_a2c2f59cb7a20d97e6e7bb024c003156.addTo(map_1bdc5db1d3ae07d87f9b6ae72721de15);\n",
       "        \n",
       "    \n",
       "            var tile_layer_8e77055d81a845412ba0abcaf3a2add1 = L.tileLayer(\n",
       "                &quot;https://earthengine.googleapis.com/v1/projects/earth-change-analysis/maps/c0bd490ab96aeeaff521c29cf5b686e6-12149ba45fa92d20119b50affcf1f302/tiles/{z}/{x}/{y}&quot;,\n",
       "                {\n",
       "  &quot;minZoom&quot;: 0,\n",
       "  &quot;maxZoom&quot;: 18,\n",
       "  &quot;maxNativeZoom&quot;: 18,\n",
       "  &quot;noWrap&quot;: false,\n",
       "  &quot;attribution&quot;: &quot;Google Earth Engine&quot;,\n",
       "  &quot;subdomains&quot;: &quot;abc&quot;,\n",
       "  &quot;detectRetina&quot;: false,\n",
       "  &quot;tms&quot;: false,\n",
       "  &quot;opacity&quot;: 1,\n",
       "}\n",
       "\n",
       "            );\n",
       "        \n",
       "    \n",
       "            tile_layer_8e77055d81a845412ba0abcaf3a2add1.addTo(map_1bdc5db1d3ae07d87f9b6ae72721de15);\n",
       "        \n",
       "    \n",
       "            var layer_control_91d8a06601e9ee8c5034fc2d9a5953a7_layers = {\n",
       "                base_layers : {\n",
       "                },\n",
       "                overlays :  {\n",
       "                    &quot;Google Satellite&quot; : tile_layer_a2c2f59cb7a20d97e6e7bb024c003156,\n",
       "                    &quot;Land Cover Classification&quot; : tile_layer_9c955a477eebaff7dc190722eb9c55a1,\n",
       "                },\n",
       "            };\n",
       "            let layer_control_91d8a06601e9ee8c5034fc2d9a5953a7 = L.control.layers(\n",
       "                layer_control_91d8a06601e9ee8c5034fc2d9a5953a7_layers.base_layers,\n",
       "                layer_control_91d8a06601e9ee8c5034fc2d9a5953a7_layers.overlays,\n",
       "                {\n",
       "  &quot;position&quot;: &quot;topright&quot;,\n",
       "  &quot;collapsed&quot;: true,\n",
       "  &quot;autoZIndex&quot;: true,\n",
       "}\n",
       "            ).addTo(map_1bdc5db1d3ae07d87f9b6ae72721de15);\n",
       "\n",
       "        \n",
       "    \n",
       "            tile_layer_a2c2f59cb7a20d97e6e7bb024c003156.addTo(map_1bdc5db1d3ae07d87f9b6ae72721de15);\n",
       "        \n",
       "    \n",
       "            tile_layer_8e77055d81a845412ba0abcaf3a2add1.addTo(map_1bdc5db1d3ae07d87f9b6ae72721de15);\n",
       "        \n",
       "    \n",
       "            var tile_layer_9c955a477eebaff7dc190722eb9c55a1 = L.tileLayer(\n",
       "                &quot;https://earthengine.googleapis.com/v1/projects/earth-change-analysis/maps/c0bd490ab96aeeaff521c29cf5b686e6-12149ba45fa92d20119b50affcf1f302/tiles/{z}/{x}/{y}&quot;,\n",
       "                {\n",
       "  &quot;minZoom&quot;: 0,\n",
       "  &quot;maxZoom&quot;: 18,\n",
       "  &quot;maxNativeZoom&quot;: 18,\n",
       "  &quot;noWrap&quot;: false,\n",
       "  &quot;attribution&quot;: &quot;Google Earth Engine&quot;,\n",
       "  &quot;subdomains&quot;: &quot;abc&quot;,\n",
       "  &quot;detectRetina&quot;: false,\n",
       "  &quot;tms&quot;: false,\n",
       "  &quot;opacity&quot;: 1,\n",
       "}\n",
       "\n",
       "            );\n",
       "        \n",
       "    \n",
       "            tile_layer_9c955a477eebaff7dc190722eb9c55a1.addTo(map_1bdc5db1d3ae07d87f9b6ae72721de15);\n",
       "        \n",
       "    \n",
       "            var layer_control_eb5ebe6eeaf7a1e395c8288c7e4c3173_layers = {\n",
       "                base_layers : {\n",
       "                },\n",
       "                overlays :  {\n",
       "                    &quot;Google Satellite&quot; : tile_layer_a2c2f59cb7a20d97e6e7bb024c003156,\n",
       "                    &quot;Land Cover Classification&quot; : tile_layer_9c955a477eebaff7dc190722eb9c55a1,\n",
       "                },\n",
       "            };\n",
       "            let layer_control_eb5ebe6eeaf7a1e395c8288c7e4c3173 = L.control.layers(\n",
       "                layer_control_eb5ebe6eeaf7a1e395c8288c7e4c3173_layers.base_layers,\n",
       "                layer_control_eb5ebe6eeaf7a1e395c8288c7e4c3173_layers.overlays,\n",
       "                {\n",
       "  &quot;position&quot;: &quot;topright&quot;,\n",
       "  &quot;collapsed&quot;: true,\n",
       "  &quot;autoZIndex&quot;: true,\n",
       "}\n",
       "            ).addTo(map_1bdc5db1d3ae07d87f9b6ae72721de15);\n",
       "\n",
       "        \n",
       "&lt;/script&gt;\n",
       "&lt;/html&gt;\" style=\"position:absolute;width:100%;height:100%;left:0;top:0;border:none !important;\" allowfullscreen webkitallowfullscreen mozallowfullscreen></iframe></div></div>"
      ],
      "text/plain": [
       "<folium.folium.Map at 0x756f916c6660>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 既存の地図 'my_map' にレイヤーを追加\n",
    "folium.TileLayer(\n",
    "    tiles=classification_tile_url,\n",
    "    attr='Google Earth Engine',\n",
    "    name='Land Cover Classification',\n",
    "    overlay=True,\n",
    "    control=True\n",
    ").add_to(my_map)\n",
    "\n",
    "folium.LayerControl().add_to(my_map)\n",
    "display(my_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d97c9e0a-984c-4291-85ec-7e16f4d0f82f",
   "metadata": {},
   "source": [
    "### **ステップ30: 分類精度の評価**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c0e63f0-785c-485f-ba9a-a709c7c17278",
   "metadata": {},
   "source": [
    "あなたは既に**教師あり分類**（水域、森林、都市）のマップを作成しましたが、その分類が**どれだけ正確**かを数値で評価することは、分析の信頼性を証明するために不可欠です。\n",
    "\n",
    "次のステップは、作成した分類器（`trained_classifier`）がどれだけ正しく各ピクセルを分類できたかを、**混同行列** ($\\text{Confusion Matrix}$) を使って分析します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "9d5462bd-0a1e-4e31-8872-1b9e08d9c9dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 分類結果を得る\n",
    "classified = sampled_data.classify(trained_classifier)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "11941614-778a-4335-bd20-990310eb1279",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: [[136848, 643, 150], [151, 136551, 939], [58, 869, 136714]]\n",
      "Overall Accuracy: 0.9931948571525442\n",
      "Kappa_coefficient: 0.9897922857288163\n"
     ]
    }
   ],
   "source": [
    "# 混同行列を計算\n",
    "confusion_matrix = classified.errorMatrix('landcover', 'classification')\n",
    "\n",
    "print('Confusion Matrix:', confusion_matrix.getInfo())\n",
    "print('Overall Accuracy:', confusion_matrix.accuracy().getInfo())\n",
    "print('Kappa_coefficient:',confusion_matrix.kappa().getInfo())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "818dc6d8-8f85-4a95-b42d-50f86482b9d7",
   "metadata": {},
   "source": [
    "ユーザー様が採用された方法は、分類器の出力を直接評価するという点で、より汎用的かつ確実な$\\text{GEE}$のパターンです。\n",
    "\n",
    "1. `sampled_data.classify`(`trained_classifier`): サンプリングデータ（訓練に使ったフィーチャコレクション）の各フィーチャを、訓練済みモデルで再分類します。結果は、`landcover`（正解）と `classification`（予測）という2つのプロパティを持つ新しいフィーチャコレクションになります。\n",
    "\n",
    "2. `classified.errorMatrix`('landcover', 'classification'): この新しいフィーチャコレクションに対して、正解ラベル (`landcover`) と 予測ラベル (`classification`) を比較して混同行列を生成します。\n",
    "\n",
    "この修正により、正確な結果を得ることができました。\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b3ab829-e352-4b5f-8074-3db2d7e31de4",
   "metadata": {},
   "source": [
    "#### **精度結果の評価**\n",
    "\n",
    "出力された精度結果は、**非常に高い**ことを示しています。\n",
    "|指標                               |結果値               |評価             |\n",
    "|----------------------------------|--------------------|-----------------|\n",
    "|全体精度 ($\\text{Overall Accuracy}$)|0.9932 (約 99.32%)  |分類の総合的な正しさを示します。全ピクセルのうち 99.32% が正しく分類されたことを意味します。                |\n",
    "カッパ係数 ($\\text{Kappa}$)          |0.9898(約 98.98%)   |偶然の一致を超えた分類の精度を示します。1 に近いほど偶然ではない高い精度であることを示し、この値0は極めて優秀です。|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c6368a6-5335-4e2f-98d0-af8c3a20e84e",
   "metadata": {},
   "source": [
    "#### **混同行列 ($\\text{Confusion Matrix}$) の解釈**\n",
    "\n",
    "|クラス (landcover)    |**水域 (0)** |**予測森林 (1)**  |**予測都市 (2)** |\n",
    "|---------------------|------------|-----------------|----------------|\n",
    "|**予測水域 (0)正解**   |136848      |643              |150             |\n",
    "|**森林 (1) 正解**     |151         |136551           |939             |\n",
    "|**都市 (2) 正解**     |58          |869              |136714          |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f9cf3a2-ee12-40df-9c43-1a17dd78dc15",
   "metadata": {},
   "source": [
    "**対角線上の値 (太字)** が**正しく分類された数**です。\n",
    "\n",
    "- **水域**は 136848 回正しく予測されましたが、643 回は森林に、150 回は都市に誤分類されました（主に水際や都市内の水路）。\n",
    "- **森林**は 136551 回正しく予測されましたが、939 回は都市に誤分類されました（都市内の公園や樹木地帯で発生）。\n",
    "- **都市**は 136714 回正しく予測されましたが、869 回は森林に誤分類されました（誤分類の多くはここでも森林との間で発生）。\n",
    "\n",
    "**総評**: 精度が非常に高いのは、**訓練に使用したデータセット（`sampled_data`）をそのまま検証に使った**ためです。これは機械学習では一般的に起こる現象ですが、手法としては正しく、分類器が訓練データセット内では完璧に機能していることが示されました。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cedc1544-2d81-4bc5-b870-f3782d9cdcb9",
   "metadata": {},
   "source": [
    "### **達成した主要な分析ステップ**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "815b1d55-eb59-43be-b84d-0ec6511c6c1d",
   "metadata": {},
   "source": [
    "|ステップ\t         |概念\t                 |GEEメソッド                                          |\n",
    "|--------------------|-----------------------|----------------------------------------------------|\n",
    "|1. データフィルタリング|必要な地域と期間の画像を取得|`ee.ImageCollection()`, `.filterBounds()`, `.filterDate()`|\n",
    "|2. クラウドマスキング\t |曇ったピクセルを透明化     |`bitwiseAnd()`, `.updateMask()`, `.map()`                |\n",
    "|3. 画像合成\t         |クリーンな画像群を1枚に集約 |`.median()`                                           |\n",
    "|4. NDVI分析\t         |植生の健全性を指数で定量化  |`.subtract()`, `.divide()`, `ee.Image.series()`           |\n",
    "|5. 土地被覆分類\t     |ピクセルをカテゴリに分類\t  |`ee.FeatureCollection()`, `.sampleRegions()`, `ee.Classifier.smileRandomForest()`, `.classify()`|  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f9c7a3d-6f3e-4ae2-b995-f0784c6f75b1",
   "metadata": {},
   "source": [
    "### **次のステップ**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f101e6ed-35b6-418f-95ee-11e92a4dda82",
   "metadata": {},
   "source": [
    "あなたは今、リモートセンシングデータを取得し、処理し、分析し、結果を地図化できる強力なスキルを持っています。今後の学習では、以下のトピックに挑戦できます。\n",
    "- **分類精度の評価**: $\\text{confusion matrix}$ を作成し、分類の正確さを数値で評価する。\n",
    "- **変化検出**: 異なる時点の画像を比較し、土地被覆の変化（例: 森林伐採、都市開発）を検出する。\n",
    "- **データのエクスポート**: 作成した分類マップを$\\text{GeoTIFF}$ファイルとして$\\text{Google Drive}$にエクスポートし、$\\text{QGIS}$などの$\\text{GIS}$ソフトウェアで利用する。\n",
    "\n",
    "この度は、GEEの高度な分析への挑戦、お疲れ様でした！また次の課題でお会いしましょう。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3fa81fa-1374-4d65-a5d5-40761cbfe0ac",
   "metadata": {},
   "source": [
    "### **ステップ31: ランダムサンプリングとテストセットによる交差検証**\n",
    "\n",
    "**課題**: サンプリングデータを訓練用とテスト用に分割し、テストデータを使って分類精度の最終評価を行ってください。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a39c83e-1f04-4ca7-81dc-23eb6a2c95d4",
   "metadata": {},
   "source": [
    "#### **Guiding Question**: 混同行列を計算する前に、`sampled_data` をランダムに $\\mathbf{70\\%}$ の訓練データと $\\mathbf{30\\%}$ のテストデータに分割するには、どの $\\text{GEE}$ メソッドを使えばよいでしょうか？"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b0c7786-868e-4518-aff2-12d50958c0b4",
   "metadata": {},
   "source": [
    "#### **Guiding Questionの解答**\n",
    "---\n",
    "```python\n",
    "ee.FeatureCollection.randomColumn()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29893309-2838-48c4-a9c4-464f3b2856b2",
   "metadata": {},
   "source": [
    "#### **課題 8-1: データのランダム分割**\n",
    "\n",
    "`ee.FeatureCollection.randomColumn()` は、フィーチャコレクションに $\\mathbf{0}$ から $\\mathbf{1}$ の間のランダムな値を持つ新しい列を追加します。この列（ここでは $\\text{'random'}$ とします）の値を使って、データセットを訓練用とテスト用に分割します。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0b6019b-4700-4087-a9d4-a90be5758f4d",
   "metadata": {},
   "source": [
    "#### **Guiding Question**:\n",
    "1. まず、`sampled_data` にランダムな値を持つ $\\text{'random'}$ という列を追加し、randomized_data に格納してください。\n",
    "2. 次に、この $\\text{random}$ 列の値が $\\mathbf{0.7}$ 未満のフィーチャを訓練データ ($\\mathbf{70\\%}$) として `training_set` に格納してください。\n",
    "\n",
    "```python\n",
    "# 1. ランダム列を追加\n",
    "randomized_data = sampled_data. # <ここに randomColumn() メソッドを記述>\n",
    "\n",
    "# 2. 訓練セット (70%未満) を抽出\n",
    "training_set = randomized_data. # <ここにフィルタリングメソッドを記述>\n",
    "\n",
    "```\n",
    "(**ヒント: フィルタリングには、以前使用した比較演算子（`.lt()`）をフィーチャコレクションに適用します**)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77091e7b-b361-4b8d-b499-efd92f604b84",
   "metadata": {},
   "source": [
    "#### **課題 8-1の解答**    \n",
    "\n",
    "---\n",
    "```python\n",
    "randomized_data = sampled_data.randomColumn()\n",
    "training_set = randomized_data.lt(0.7)\n",
    "```\n",
    "<span style='color:red'>Wrong!</span>\n",
    "---\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ace74355-84fa-486a-80de-8187c8f5b31e",
   "metadata": {},
   "source": [
    "#### **修正点: `filter()` メソッドの使用**\n",
    "\n",
    "`randomized_data` は $\\text{ee.FeatureCollection}$ であり、`.lt(0.7)` のような比較演算子を直接適用することはできません。フィーチャコレクションをフィルタリングするには、以前学んだ `.filter()` メソッドと、その内部で $\\text{ee.Filter}$ を使用する必要があります。今回は、フィーチャコレクションに既にある列（'random'）の値に基づくフィルタリングなので、`ee.Filter.lt()` を使用します。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1813269d-5422-426f-a32f-11620093a056",
   "metadata": {},
   "source": [
    "<span style='color:blue'>**フィーチャーコレクション（FeatureCollection）とは?**</span>\n",
    "---\n",
    "\n",
    "Google Earth Engine における「ベクトルデータの集合」を表すオブジェクトです。点・線・ポリゴンなどの地理的形状（Feature）と、それに付随する属性情報をまとめて扱うための基本的なデータ構造です。\n",
    "\n",
    "---\n",
    "**基本的な概念**\n",
    "- **Feature（フィーチャー）**\n",
    "→ ジオメトリ（点・線・ポリゴンなど）＋属性（例えば土地利用区分、人口、標高など）を持つ単位。\n",
    "- **FeatureCollection（フィーチャーコレクション）**\n",
    "→ 複数の Feature をまとめた「テーブル形式のベクトルデータ」。\n",
    "→ 例：市区町村境界の集合、観測点の集合、土地被覆分類のサンプル点など。\n",
    "\n",
    "---\n",
    "**特徴**\n",
    "- **テーブルデータのように扱える**\n",
    "→ 各 Feature は「行」、属性は「列」として整理される。\n",
    "- **ジオメトリを持つ**\n",
    "→ 単なる表ではなく、空間的な位置情報を保持。\n",
    "- **演算が可能**\n",
    "→ フィルタリング、結合、集計、地図への可視化などが可能。\n",
    "- **入力データとして利用**\n",
    "→ 機械学習分類器のトレーニングデータや、統計解析の対象として使える。\n",
    "\n",
    "---\n",
    "**使用例（JavaScript API）**\n",
    "```javascript\n",
    "// 例: 世界のエコリージョンを読み込む\n",
    "var ecoregions = ee.FeatureCollection('RESOLVE/ECOREGIONS/2017');\n",
    "\n",
    "// 属性をフィルタリング\n",
    "var asiaRegions = ecoregions.filter(ee.Filter.eq('realm', 'Indo-Malay'));\n",
    "\n",
    "// 地図に表示\n",
    "Map.addLayer(asiaRegions, {color: 'FF0000'}, 'Asia Ecoregions');\n",
    "```\n",
    "\n",
    "---\n",
    "**活用場面**\n",
    "- **分類器のトレーニングデータ**\n",
    "→ サンプル点を FeatureCollection として準備し、train() に渡す。\n",
    "- **統計解析**\n",
    "→ reduceColumns() や aggregate_* 関数で属性値を集計。\n",
    "- **可視化**\n",
    "→ Map.addLayer() で地図上に表示。\n",
    "\n",
    "---\n",
    "**まとめ**\n",
    "FeatureCollection は「地理的形状＋属性情報」を持つ Feature の集合で、GEE におけるベクトルデータの基本単位です。画像（Raster）と並んで、解析や可視化の中心的役割を果たします。\n",
    "\n",
    "---\n",
    "例えば「京都市の緑地分布をポリゴンで整理したデータ」や「観測点の座標＋温度属性」を FeatureCollection として扱うと、分類器のトレーニングや都市環境解析に直結します。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "494602ac-2ed3-46a0-9491-7389ccfdd119",
   "metadata": {},
   "source": [
    "`ee.FeatureCollection.filter` と `ee.Filter.lt` は似たように見えますが、役割が違います。\n",
    "\n",
    "---\n",
    "`ee.FeatureCollection.filter`\n",
    "- **対象**: フィーチャーコレクション（FeatureCollection）\n",
    "- **役割**: コレクションに「フィルタ条件」を適用して、条件に合うフィーチャーだけを残す。\n",
    "\n",
    "---\n",
    "`ee.Filter.lt`\n",
    "- **対象**: フィルタ条件そのもの\n",
    "- **役割**: 「属性値が指定値より小さい」という条件を定義する。\n",
    "\n",
    "---\n",
    "**両者の関係**\n",
    "- `ee.Filter.lt` は 条件を作る。\n",
    "- `ee.FeatureCollection.filter` は その条件を適用する。\n",
    "```python\n",
    "# フィルタ条件を作成\n",
    "filter_condition = ee.Filter.lt('elevation', 1000)\n",
    "\n",
    "# フィーチャーコレクションに適用\n",
    "filtered_fc = feature_collection.filter(filter_condition)\n",
    "```\n",
    "---\n",
    "**まとめ**\n",
    "- `ee.Filter.lt` → 「条件を定義する」\n",
    "- `ee.FeatureCollection.filter` → 「その条件でコレクションを絞り込む」\n",
    "\n",
    "---\n",
    "例えば「京都市内の観測点 FeatureCollection から標高 50m 未満の点だけ抽出する」ときに、この組み合わせが役立ちます。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a28ee4be-e36e-4144-ae63-215653e1eb43",
   "metadata": {},
   "source": [
    "```python\n",
    "import ee\n",
    "ee.Initialize()\n",
    "\n",
    "# 例: 京都市の行政境界を読み込む（ここでは簡単に日本の行政境界データセットを利用）\n",
    "kyoto = ee.FeatureCollection(\"FAO/GAUL/2015/level2\") \\\n",
    "    .filter(ee.Filter.eq('ADM2_NAME', 'Kyoto'))\n",
    "\n",
    "# 標高データ（SRTM）\n",
    "elevation = ee.Image(\"USGS/SRTMGL1_003\")\n",
    "\n",
    "# 土地利用データ（MODIS Land Cover）\n",
    "landcover = ee.Image(\"MODIS/006/MCD12Q1/2019_01_01\") \\\n",
    "    .select('LC_Type1')\n",
    "\n",
    "# --- フィルタリング条件 ---\n",
    "# 標高が50m未満の地域\n",
    "low_elev = elevation.lt(50)\n",
    "\n",
    "# 土地利用属性: 例えば「草地 (class=10)」を抽出\n",
    "grassland = landcover.eq(10)\n",
    "\n",
    "# --- 条件を組み合わせてマスク ---\n",
    "green_area_mask = low_elev.And(grassland)\n",
    "\n",
    "# 京都市の範囲でマスクを適用\n",
    "green_area = landcover.updateMask(green_area_mask).clip(kyoto)\n",
    "\n",
    "# 地図に表示（JavaScript APIなら Map.addLayer）\n",
    "# Python APIでは結果をエクスポートするか、foliumで表示する\n",
    "print(\"緑地解析のマスクが作成されました\")\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "697f5476-257e-4e52-bdbd-40f539d70e56",
   "metadata": {},
   "source": [
    "#### **課題 8-1の解答** （修正後）\n",
    "\n",
    "---\n",
    "```python\n",
    "# 1. ランダム列を追加 (ここまでは完璧です)\n",
    "randomized_data = sampled_data.randomColumn()\n",
    "\n",
    "# 2. 訓練セット (70%未満) を抽出\n",
    "# 修正点: .filter() と ee.Filter.lt() を使って、'random' 列を比較します\n",
    "training_set = randomized_data.filter(ee.Filter.lt('random', 0.7))\n",
    "```\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "206e5606-4463-4bd4-ba1a-dc1aec5fa3ca",
   "metadata": {},
   "source": [
    "#### **課題 8-2: テストセットの抽出**\n",
    "\n",
    "これで訓練データ（$\\mathbf{70\\%}$）ができました。次に、残りの $\\mathbf{30\\%}$ をテストデータとして抽出する必要があります。\n",
    "\n",
    "#### **Guiding Question**: $\\text{random}$ 列の値が $\\mathbf{0.7}$ 以上のフィーチャをテストデータ ($\\mathbf{30\\%}$) として `testing_set` に格納するには、どの $\\text{ee.Filter}$ メソッドを使えばよいでしょうか？\n",
    "```python\n",
    "# ヒント: 比較演算子（.lt() や .gt()）のうち、境界値も含むメソッドを使います。\n",
    "\n",
    "testing_set = randomized_data.filter(ee.Filter. # <ここにフィルタリングメソッドを記述> ('random', 0.7))\n",
    "```\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b5d9a80-ec9e-4c39-b43e-30ed0e9d4736",
   "metadata": {},
   "source": [
    "#### **課題 8-2の解答**\n",
    "\n",
    "---\n",
    "```python\n",
    "testing_set = randomized_data.filter(ee.Filter.lte('random', 0.3))\n",
    "```\n",
    "\n",
    "<span style='color:red'>Wrong</span>\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cd30577-7f14-4823-acb5-04d84e93fc76",
   "metadata": {},
   "source": [
    "全体の $\\mathbf{30\\%}$ を抽出するには、$\\mathbf{0.7}$ 以上の値を抽出する必要があります。 \n",
    "\n",
    "**テストセットのフィルタリングの修正**\n",
    "1. 訓練セット: $\\text{random} < 0.7$ ($\\mathbf{70\\%}$)\n",
    "2. テストセット: $\\text{random} \\ge 0.7$ ($\\mathbf{30\\%}$)$\\text{ee.Filter.lte()}$ を使う場合、以下のように修正する必要があります。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18595e80-fef1-487a-98e9-7c4d1dd1902b",
   "metadata": {},
   "source": [
    "#### **課題 8-2の解答**（修正後）\n",
    "\n",
    "---\n",
    "\n",
    "```python\n",
    "# 修正点: 0.7 以下の値ではなく、0.7 以上の値を抽出するフィルターが必要です。\n",
    "\n",
    "# 0.7以上の値を抽出するためのフィルター\n",
    "# 以下のどちらかを使用します:\n",
    "# 1. ee.Filter.gte('random', 0.7)  (greater than or equal to 0.7)\n",
    "# 2. ee.Filter.gt('random', 0.7)   (greater than 0.7, 簡単のためこちらを使用)\n",
    "\n",
    "testing_set = randomized_data.filter(ee.Filter.gte('random', 0.7))\n",
    "\n",
    "```\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0dfae0c-4ab4-42ad-9dd6-18f5912ba9f1",
   "metadata": {},
   "source": [
    "これで、訓練データとテストデータが以下の通り正しく分割されました。\n",
    "\n",
    "- training_set: $\\text{random} < 0.7$\n",
    "- testing_set: $\\text{random} \\ge 0.7$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ef84d38-e542-43f4-9a85-6a3dd2aa56c0",
   "metadata": {},
   "source": [
    "## **ステップ32: 交差検証による分類精度の評価**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c01c8dc-341d-4376-a6ef-69492be03dc6",
   "metadata": {},
   "source": [
    "これで、分類の信頼性を評価するための理想的なデータセットが揃いました。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18e7f782-5144-49c1-a7ee-00f0717bda39",
   "metadata": {},
   "source": [
    "#### **課題 9-1**: \n",
    "\n",
    "分類器の再訓練とテストデータの分類まず、$\\mathbf{70\\%}$ の訓練データ (`training_set`) を使って分類器を再訓練し、その分類器を $\\mathbf{30\\%}$ のテストデータ (`testing_set`) に適用します。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d17b6615-76ec-4771-87a1-74b21ac9cb1d",
   "metadata": {},
   "source": [
    "#### **Guiding Question:**\n",
    "\n",
    "1. `training_set` を使って分類器を再訓練し、`trained_classifier_test` に格納してください。\n",
    "2. `testing_set` にこの分類器を適用し、結果を `test_classified` に格納してください。\n",
    "\n",
    "```pytnon \n",
    "# 1. 訓練セットで分類器を再訓練 (以前の訓練コードと同じ)\n",
    "trained_classifier_test = ee.Classifier.smileRandomForest(10).train(\n",
    "    features=training_set,\n",
    "    classProperty='landcover',\n",
    "    inputProperties=input_bands\n",
    ")\n",
    "\n",
    "# 2. テストセットに適用 (予測の実行)\n",
    "test_classified = testing_set. # <ここに classify メソッドを記述>\n",
    "\n",
    "```\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7cfc7ee-6d3d-4430-8fe9-6314200fc612",
   "metadata": {},
   "source": [
    "#### **課題 9-2の解答**\n",
    "\n",
    "---\n",
    "```python\n",
    "test_classified = testing_set.classify(trained_classifier_test)\n",
    "\n",
    "```\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1ffae18-22f1-4f96-aed5-a53665162085",
   "metadata": {},
   "source": [
    "## **ステップ33: テストセットによる最終評価**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4ea73ce-45ca-4af2-b8b2-e92fcd5bdac9",
   "metadata": {},
   "source": [
    "これで、訓練に使われていないデータ（`testing_set`）に対する予測結果 (`test_classified`) が得られました。いよいよ、このデータを使って**分類の真の精度**を評価します。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e58e50c0-35c9-4f81-b9b7-1d7f21ffd5b9",
   "metadata": {},
   "source": [
    "#### **課題 9-2: 交差検証後の精度計算**\n",
    "\n",
    "以前成功した方法（`.errorMatrix()`）を使って、テストセットにおける混同行列を計算し、全体精度とカッパ係数を抽出します。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84481e15-2ad5-4333-9114-ca16fadbbf37",
   "metadata": {},
   "source": [
    "#### **Guiding Question**: 上記のコードを実行した後、以下のコードを実行して、訓練されていないデータに対する最終的な全体精度とカッパ係数の値を確認してください。これらの値は、訓練データを使ったとき（約 $\\text{0.99}$）と比較して、**高くなりましたか？低くなりましたか？**\n",
    "\n",
    "---\n",
    "```python\n",
    "# 1. 混同行列を計算 (テストセットの正解と予測を比較)\n",
    "test_confusion_matrix = test_classified.errorMatrix('landcover', 'classification')\n",
    "\n",
    "# 2. 結果を出力\n",
    "print(\"--- テストセットによる精度評価 ---\")\n",
    "print('Overall Accuracy:', test_confusion_matrix.accuracy().getInfo())\n",
    "print('Kappa Coefficient:', test_confusion_matrix.kappa().getInfo())\n",
    "```\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "1d9cf5e3-01dc-4ea6-a7df-9a47b710ff90",
   "metadata": {},
   "outputs": [],
   "source": [
    "randomized_data = sampled_data.randomColumn()\n",
    "training_set = randomized_data.filter(ee.Filter.lt('random', 0.7))\n",
    "testing_set = randomized_data.filter(ee.Filter.gte('random', 0.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "b0368918-a842-4ee8-9f4f-667e946058ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_classifier_test = ee.Classifier.smileRandomForest(10).train(\n",
    "    features=training_set,\n",
    "    classProperty='landcover',\n",
    "    inputProperties=input_bands\n",
    ")\n",
    "\n",
    "test_classified = testing_set.classify(trained_classifier_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "16445340-9756-4f5e-bc33-35b1ea0956a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- テストセットによる精度評価 ---\n",
      "Test Cofusion Matrix: [[39674, 1278, 306], [421, 38772, 1927], [109, 1490, 39748]]\n",
      "Overall Accuracy: 0.9552960193978581\n",
      "Kappa Coefficient: 0.9329438672548739\n"
     ]
    }
   ],
   "source": [
    "# 1. 混同行列を計算 (テストセットの正解と予測を比較)\n",
    "test_confusion_matrix = test_classified.errorMatrix('landcover', 'classification')\n",
    "\n",
    "# 2. 結果を出力\n",
    "print(\"--- テストセットによる精度評価 ---\")\n",
    "print('Test Cofusion Matrix:', test_confusion_matrix.getInfo())\n",
    "print('Overall Accuracy:', test_confusion_matrix.accuracy().getInfo())\n",
    "print('Kappa Coefficient:', test_confusion_matrix.kappa().getInfo())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35d9ebf6-b8ec-4210-bb32-6d9348cd9e36",
   "metadata": {},
   "source": [
    "#### **課題 9-2の解答**\n",
    "\n",
    "---\n",
    "分析結果は、低くなります。\n",
    "\n",
    "---\n",
    "#### **結果の分析:**\n",
    "交差検証の成功訓練に使用しなかったデータ（**テストセット**）で精度を評価した結果、以前の全体精度（約 $\\text{0.99}$）よりも数値が下がったことは、交差検証が**正しく機能している**ことを示しています。\n",
    "\n",
    "- **訓練データでの精度**: 分類器が学習時に見たデータに対する性能 (通常は過大評価される)。\n",
    "- **テストデータでの精度**: 分類器が学習時に見なかったデータに対する性能 (真の汎化能力)。\n",
    "\n",
    "全体精度とカッパ係数が低下したということは、この分類器の**真の汎化能力**（未知の画像に適用した際の予測精度）は $\\text{0.99}$ ではなく、テストセットで得られた**低い方の値**に近いと判断できます。このプロセスを通じて、あなたは機械学習モデルの訓練だけでなく、その結果を**客観的に評価し、信頼性を確保する**という、実践的な地理空間分析の最終ステップを習得しました。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f6b3c3b-98c3-4807-904b-a9344451f88b",
   "metadata": {},
   "source": [
    "## **学習の完了: 総合地理空間分析**\n",
    "---\n",
    "これで、**多様な衛星画像**と**様々な解析手法を組み合わせた**、非常に包括的な$\\text{Google Earth Engine}$の学習を完了しました。\n",
    "\n",
    "あなたが習得したスキルは、実務や研究において、地球規模のデータを扱うための強力な基盤となります。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
